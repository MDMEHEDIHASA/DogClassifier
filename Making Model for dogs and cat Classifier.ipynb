{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_x7vBfavKDwB"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7958,
     "status": "ok",
     "timestamp": 1758767603378,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "sQahalZES-oK",
    "outputId": "6a7c7581-70ff-48b7-c77e-1255f8054ab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbaVcCxhTOS-"
   },
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4436,
     "status": "ok",
     "timestamp": 1758767607825,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "GTXedsBfTqzt",
    "outputId": "88daf175-8d18-4889-adc8-9f00a8be58a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20580 files belonging to 120 classes.\n",
      "Using 16464 files for training.\n"
     ]
    }
   ],
   "source": [
    "# train dataset\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"Images\",\n",
    "    validation_split=0.2, # 80/20 split\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1146,
     "status": "ok",
     "timestamp": 1758767608985,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "0vG7Ga85Tw1a",
    "outputId": "62044c8e-90b0-422a-9021-fc6a47e4dd09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20580 files belonging to 120 classes.\n",
      "Using 4116 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# validation dataset\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"Images\",\n",
    "    validation_split=0.2, # 80/20 split\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1758767609004,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "IALPR5zpUfdr",
    "outputId": "b082cf5c-eefb-48dd-c931-1240eab3356e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of breeds: 120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Number of breeds:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htsmjOebVDDS"
   },
   "source": [
    "# Step 3: Data Augmentation + Prefetch\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXFeH10_VHLu"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds   = val_ds.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2570,
     "status": "ok",
     "timestamp": 1758767611582,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "Prd9EtGGVg1N",
    "outputId": "738119f5-0901-41cd-b4c3-4df573f75e7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50(\n",
    "    input_shape=img_size + (3,),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XzLQvEA5WAjx"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False  # freeze backbone for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgWqEQloW_Rg"
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=img_size + (3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WaOIPd9OXvqG"
   },
   "outputs": [],
   "source": [
    "x = tf.keras.applications.resnet50.preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yG_S4axdYgmi"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24A91EFeYvLc"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOTd28tLZMjZ"
   },
   "source": [
    "# Step 5: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2358003,
     "status": "ok",
     "timestamp": 1758769969662,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "_ZeWdgNZZO7I",
    "outputId": "956bb9a1-b32c-438a-888d-cc30a5284faa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 469ms/step - accuracy: 0.0706 - loss: 4.6093 - val_accuracy: 0.5046 - val_loss: 2.2767\n",
      "Epoch 2/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 438ms/step - accuracy: 0.3969 - loss: 2.4860 - val_accuracy: 0.6601 - val_loss: 1.4322\n",
      "Epoch 3/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 436ms/step - accuracy: 0.5497 - loss: 1.7459 - val_accuracy: 0.7150 - val_loss: 1.1216\n",
      "Epoch 4/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 446ms/step - accuracy: 0.6379 - loss: 1.4042 - val_accuracy: 0.7357 - val_loss: 0.9703\n",
      "Epoch 5/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 447ms/step - accuracy: 0.6769 - loss: 1.2028 - val_accuracy: 0.7505 - val_loss: 0.8841\n",
      "Epoch 6/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 437ms/step - accuracy: 0.6937 - loss: 1.0980 - val_accuracy: 0.7573 - val_loss: 0.8315\n",
      "Epoch 7/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 438ms/step - accuracy: 0.7227 - loss: 0.9897 - val_accuracy: 0.7721 - val_loss: 0.7883\n",
      "Epoch 8/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 439ms/step - accuracy: 0.7408 - loss: 0.9189 - val_accuracy: 0.7709 - val_loss: 0.7639\n",
      "Epoch 9/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 436ms/step - accuracy: 0.7509 - loss: 0.8717 - val_accuracy: 0.7750 - val_loss: 0.7417\n",
      "Epoch 10/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 435ms/step - accuracy: 0.7637 - loss: 0.8266 - val_accuracy: 0.7767 - val_loss: 0.7271\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1505423,
     "status": "ok",
     "timestamp": 1758771475256,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "HKaTkajVZR4l",
    "outputId": "24fc61e8-7ae2-4980-a553-789e86395254"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1758771475602,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "KSi-vrl0jF8-",
    "outputId": "6b64b450-e13a-494b-ec2d-6ac3c967fe18"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1758771556876,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "m2lSdW4RpjYO",
    "outputId": "939c2d24-2ae4-4e37-f75f-f778c8c8d55a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Path to image you want to test\n",
    "img_path = \"/content/drive/MyDrive/Colab Notebooks/Project Unique/Dog test/hero_belgian_malinois.avif\"\n",
    "\n",
    "# Trying a more common path for mounted Google Drive files\n",
    "#img_path = \"/content/drive/MyDrive/GR.webp\"\n",
    "\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # shape (1, 224, 224, 3)\n",
    "\n",
    "# Use preprocess_input if using a pretrained backbone\n",
    "img_array = tf.keras.applications.resnet50.preprocess_input(img_array) # Use resnet50 preprocess_input\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(img_array)  # shape (1, num_classes)\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "predicted_class_name = class_names[predicted_class_index]\n",
    "\n",
    "print(f\"Predicted Breed: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2zWZzC0rJhn"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/stanford_dogs_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2190,
     "status": "ok",
     "timestamp": 1758771921737,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "-Jet5P7ar64z",
    "outputId": "416c2cd9-099d-4e40-8c7e-038fd8cc5685"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"/content/drive/MyDrive/stanford_dogs_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0tH8ESia_POh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/best_model.keras\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             save_best_only=True,\n",
    "                             mode=\"max\")\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=10,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfnT5sgrKG5T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABMvZqY9KIK5"
   },
   "source": [
    "# For making classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206343,
     "status": "ok",
     "timestamp": 1758775402356,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "xAmclzEGKl5K",
    "outputId": "79f9cde6-fe9c-43e5-d22e-f9e1df22580b"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "tar_path = \"/content/drive/MyDrive/Colab Notebooks/Project Unique/Dog Dataset/images.tar\"\n",
    "extract_dir = \"/content/drive/MyDrive/Colab Notebooks/Project Unique/Dog Dataset/images\"  # where to extract\n",
    "\n",
    "# Create target directory if not exists\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Extract\n",
    "with tarfile.open(tar_path, \"r\") as tar:\n",
    "    tar.extractall(path=extract_dir)\n",
    "\n",
    "print(\"‚úÖ Extracted to:\", extract_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1758775739631,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "cVmdsWX3Mgjx",
    "outputId": "4ef2c52f-5ad9-464f-b39d-52a2639277e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 120\n",
      "Sample: ['Chihuahua', 'Japanese spaniel', 'Maltese dog', 'Pekinese', 'Shih-Tzu', 'Blenheim spaniel', 'papillon', 'toy terrier', 'Rhodesian ridgeback', 'Afghan hound']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_dir = \"/content/drive/MyDrive/Colab Notebooks/Project Unique/Dog Dataset/images/Images\"\n",
    "folders = sorted(os.listdir(dataset_dir))  # sorted to match training order\n",
    "class_names = []\n",
    "\n",
    "for f in folders:\n",
    "    if os.path.isdir(os.path.join(dataset_dir, f)):  # ensure it's a folder\n",
    "        name = f.split('-', 1)[-1].replace('_', ' ')\n",
    "        class_names.append(name)\n",
    "\n",
    "print(\"Total classes:\", len(class_names))\n",
    "print(\"Sample:\", class_names[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DFF2BljKN40"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/Colab Notebooks/Project Unique/standfordDogClasses.txt\", \"w\") as f:\n",
    "    for name in class_names:\n",
    "        f.write(name + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIrtiO00QRjS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17175,
     "status": "ok",
     "timestamp": 1758855316994,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "s2PrxAtX8X1Z",
    "outputId": "4f38ee61-8716-4927-b838-a807d0d5f025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 33763,
     "status": "ok",
     "timestamp": 1758855379351,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "0_ThFzYUQ5eD",
    "outputId": "f985d851-2884-4220-8b4a-10eda2b33c70"
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Install packages\n",
    "# --------------------------\n",
    "!pip install ultralytics opencv-python-headless matplotlib tensorflow\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --------------------------\n",
    "# 1. Load Models\n",
    "# --------------------------\n",
    "detector = YOLO(\"yolov8n.pt\")  # YOLOv8 object detector (for dog detection)\n",
    "breed_classifier_model = load_model(\"/content/drive/MyDrive/stanford_dogs_model.keras\")\n",
    "\n",
    "# Load your custom breed class names (must match training order)\n",
    "with open(\"/content/drive/MyDrive/Colab Notebooks/Project Unique/standfordDogClasses.txt\") as f:\n",
    "    class_names = [line.strip() for line in f]\n",
    "\n",
    "# --------------------------\n",
    "# 2. Download or Load a Sample Dog Image\n",
    "# --------------------------\n",
    "url = \"https://static.vecteezy.com/system/resources/previews/005/857/332/non_2x/funny-portrait-of-cute-corgi-dog-outdoors-free-photo.jpg\"\n",
    "img_path = \"/content/drive/MyDrive/Colab Notebooks/Project Unique/Dog test/zs.webp\"\n",
    "\n",
    "if not os.path.exists(img_path):\n",
    "    r = requests.get(url, stream=True)\n",
    "    r.raise_for_status()\n",
    "    with open(img_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "# --------------------------\n",
    "# 3. Run YOLO Detection\n",
    "# --------------------------\n",
    "try:\n",
    "    img_pil = Image.open(img_path).convert(\"RGB\")  # Ensure RGB\n",
    "    img_array = np.array(img_pil)\n",
    "    results = detector(img_array)  # Run YOLO detection\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or processing image: {e}\")\n",
    "    results = None\n",
    "\n",
    "# --------------------------\n",
    "# 4. Crop Dog Regions\n",
    "# --------------------------\n",
    "dog_crops = []\n",
    "if results and results[0].boxes is not None:\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()   # Bounding boxes (x1,y1,x2,y2)\n",
    "    labels = results[0].boxes.cls.cpu().numpy()   # Class labels\n",
    "    img_cv = cv2.imread(img_path)                 # Load for cropping (BGR)\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        if int(labels[i]) == 16:  # COCO class 16 = dog\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            h, w, _ = img_cv.shape\n",
    "            x1, y1, x2, y2 = max(0,x1), max(0,y1), min(w,x2), min(h,y2)\n",
    "            if x2 > x1 and y2 > y1:\n",
    "                dog_crop = img_cv[y1:y2, x1:x2]\n",
    "                dog_crops.append(dog_crop)\n",
    "else:\n",
    "    print(\"No dogs detected.\")\n",
    "\n",
    "# --------------------------\n",
    "# 5. Breed Classification\n",
    "# --------------------------\n",
    "predictions = []\n",
    "if dog_crops:\n",
    "    for i, crop in enumerate(dog_crops):\n",
    "        crop_path = f\"dog_crop_{i}.jpg\"\n",
    "        cv2.imwrite(crop_path, crop)\n",
    "\n",
    "        try:\n",
    "            img = image.load_img(crop_path, target_size=(224,224))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)  # Same preprocessing used in training\n",
    "\n",
    "            preds = breed_classifier_model.predict(x)  # (1, num_classes)\n",
    "            probs = preds[0]\n",
    "            top_indices = probs.argsort()[-3:][::-1]  # Top 3 predictions\n",
    "            decoded = [(class_names[j], float(probs[j])) for j in top_indices]\n",
    "            predictions.append(decoded)\n",
    "        except Exception as e:\n",
    "            print(f\"Error classifying dog crop {i}: {e}\")\n",
    "            predictions.append(f\"Classification Error: {e}\")\n",
    "\n",
    "# --------------------------\n",
    "# 6. Display Results\n",
    "# --------------------------\n",
    "if results:\n",
    "    res_plot = results[0].plot()\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1, max(1, len(dog_crops) + (1 if dog_crops else 0)), 1)\n",
    "    plt.imshow(cv2.cvtColor(res_plot, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Detected Dog(s)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "if dog_crops:\n",
    "    for i, crop in enumerate(dog_crops):\n",
    "        plt.subplot(1, max(1, len(dog_crops) + (1 if results else 0)), i + (2 if results else 1))\n",
    "        plt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Cropped Dog {i+1}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# 7. Print Breed Predictions\n",
    "# --------------------------\n",
    "if predictions:\n",
    "    for i, decoded in enumerate(predictions):\n",
    "        print(f\"üêï Dog {i+1} Breed Predictions:\")\n",
    "        if isinstance(decoded, list):\n",
    "            for (breed, score) in decoded:\n",
    "                print(f\" - {breed} ({score*100:.2f}%)\")\n",
    "        else:\n",
    "            print(decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yzXnoOHQ69s"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIJMOymUT1Kc"
   },
   "source": [
    "# ‚úÖ  Wrap into a function / API\n",
    "\n",
    "Instead of running everything in a notebook cell, wrap the pipeline into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23924,
     "status": "ok",
     "timestamp": 1758858651695,
     "user": {
      "displayName": "mehedi hasan",
      "userId": "04144062826998183307"
     },
     "user_tz": 240
    },
    "id": "f-bgM-ttP7Fx",
    "outputId": "556c4014-e7a5-4ce9-dde7-40e319daaedc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from flask import Flask, request, jsonify\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input  # Add this import\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# ----------------------------\n",
    "# [INFO] Load models\n",
    "# ----------------------------\n",
    "print(\"[INFO] Loading YOLO model...\")\n",
    "yolo = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "print(\"[INFO] Loading custom breed model...\")\n",
    "classifier = load_model(\"/content/drive/MyDrive/stanford_dogs_model.keras\")\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Colab Notebooks/Project Unique/standfordDogClasses.txt\") as f:\n",
    "    BREED_CLASSES = [line.strip() for line in f]\n",
    "\n",
    "# ----------------------------\n",
    "# Helper function\n",
    "# ----------------------------\n",
    "def predict_breed(img_path):\n",
    "    try:\n",
    "        # Load image as PIL Image first (like in working code)\n",
    "        img_pil = Image.open(img_path).convert(\"RGB\")\n",
    "        img_array = np.array(img_pil)\n",
    "\n",
    "        # Detect dog with YOLO\n",
    "        results = yolo(img_array)\n",
    "\n",
    "        # Check if any dogs were detected\n",
    "        if results[0].boxes is None:\n",
    "            return {\"error\": \"No dogs detected\"}\n",
    "\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        labels = results[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "        # Find the first dog (COCO class 16)\n",
    "        dog_box = None\n",
    "        for i, box in enumerate(boxes):\n",
    "            if int(labels[i]) == 16:  # COCO class 16 = dog\n",
    "                dog_box = box\n",
    "                break\n",
    "\n",
    "        if dog_box is None:\n",
    "            return {\"error\": \"No dog detected\"}\n",
    "\n",
    "        # Crop the dog region\n",
    "        x1, y1, x2, y2 = map(int, dog_box)\n",
    "\n",
    "        # Load image with OpenCV for cropping (like in working code)\n",
    "        img_cv = cv2.imread(img_path)\n",
    "        h, w, _ = img_cv.shape\n",
    "\n",
    "        # Ensure coordinates are within bounds\n",
    "        x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)\n",
    "\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return {\"error\": \"Invalid crop dimensions\"}\n",
    "\n",
    "        dog_crop = img_cv[y1:y2, x1:x2]\n",
    "\n",
    "        # Save cropped image temporarily\n",
    "        crop_path = \"temp_crop.jpg\"\n",
    "        cv2.imwrite(crop_path, dog_crop)\n",
    "\n",
    "        # Load and preprocess exactly like in working code\n",
    "        img = image.load_img(crop_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)  # Use ResNet50 preprocessing instead of /255.0\n",
    "\n",
    "        # Predict\n",
    "        preds = classifier.predict(x)\n",
    "\n",
    "        # Get top 3 predictions like in working code\n",
    "        probs = preds[0]\n",
    "        top_indices = probs.argsort()[-3:][::-1]  # Top 3 predictions\n",
    "\n",
    "        top_predictions = []\n",
    "        for idx in top_indices:\n",
    "            breed_name = BREED_CLASSES[idx]\n",
    "            confidence = float(probs[idx])\n",
    "            top_predictions.append({\n",
    "                \"breed\": breed_name,\n",
    "                \"confidence\": confidence\n",
    "            })\n",
    "\n",
    "        print(\"Check top predictions---------->\", top_predictions)\n",
    "\n",
    "        # Clean up temporary file\n",
    "        if os.path.exists(crop_path):\n",
    "            os.remove(crop_path)\n",
    "\n",
    "        #return {\n",
    "        #    \"top_prediction\": top_predictions[0],\n",
    "        #    \"all_predictions\": top_predictions\n",
    "        #}\n",
    "        return {\n",
    "            \"breed\": top_predictions[0][\"breed\"],\n",
    "            \"confidence\": top_predictions[0][\"confidence\"]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in predict_breed: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# ----------------------------\n",
    "# Flask API\n",
    "# ----------------------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No file uploaded\"}), 400\n",
    "\n",
    "    f = request.files[\"file\"]\n",
    "    if f.filename == '':\n",
    "        return jsonify({\"error\": \"No file selected\"}), 400\n",
    "\n",
    "    filepath = os.path.join(\"uploads\", f.filename)\n",
    "    os.makedirs(\"uploads\", exist_ok=True)\n",
    "    f.save(filepath)\n",
    "\n",
    "    try:\n",
    "        result = predict_breed(filepath)\n",
    "        # Clean up uploaded file\n",
    "        if os.path.exists(filepath):\n",
    "            os.remove(filepath)\n",
    "        return jsonify(result)\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RouSZnXQV7kt"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2o19hEzBKo6z"
   },
   "source": [
    "# For Dog adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ibw_upInKsgN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from flask import Flask, request, jsonify\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input  # Add this import\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# ----------------------------\n",
    "# [INFO] Load models\n",
    "# ----------------------------\n",
    "print(\"[INFO] Loading YOLO model...\")\n",
    "yolo = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "print(\"[INFO] Loading custom breed model...\")\n",
    "classifier = load_model(\"stanford_dogs_model.keras\")\n",
    "\n",
    "with open(\"standfordDogClasses.txt\") as f:\n",
    "    BREED_CLASSES = [line.strip() for line in f]\n",
    "\n",
    "# ----------------------------\n",
    "# Helper function to generate dog links\n",
    "# ----------------------------\n",
    "def get_dog_links(breed_name):\n",
    "    \"\"\"Generate links for buying/adopting the predicted dog breed\"\"\"\n",
    "    # Clean breed name for URL (replace underscores with spaces, handle special characters)\n",
    "    clean_breed = breed_name.replace(\"_\", \" \").replace(\"-\", \" \").title()\n",
    "    url_breed = breed_name.replace(\"_\", \"%20\").replace(\" \", \"%20\")\n",
    "\n",
    "    links = {\n",
    "        \"adoption\": {\n",
    "            \"petfinder\": f\"https://www.petfinder.com/dog-breeds/{breed_name.lower().replace('_', '-')}/\",\n",
    "            https://www.petfinder.com/search/dogs-for-adoption/?breed[]=Golden%20Retriever\n",
    "            \"adopt_a_pet\": f\"https://www.adoptapet.com/dog-adoption/breed/{url_breed}\",\n",
    "            \"rescue_groups\": f\"https://www.akc.org/dog-breeds/{breed_name.lower().replace('_', '-')}/rescue-groups/\"\n",
    "        },\n",
    "        \"purchase\": {\n",
    "            \"akc_marketplace\": f\"https://marketplace.akc.org/puppies/browse?breed={url_breed}\",\n",
    "            \"puppyfind\": f\"https://www.puppyfind.com/breed/{breed_name.lower().replace('_', '')}\",\n",
    "            \"nextdaypets\": f\"https://www.nextdaypets.com/{breed_name.lower().replace('_', '')}-puppies-for-sale\"\n",
    "        },\n",
    "        \"breed_info\": {\n",
    "            \"akc_info\": f\"https://www.akc.org/dog-breeds/{breed_name.lower().replace('_', '-')}/\",\n",
    "            \"dogtime\": f\"https://dogtime.com/dog-breeds/{breed_name.lower().replace('_', '-')}\",\n",
    "            \"wikipedia\": f\"https://en.wikipedia.org/wiki/{clean_breed}\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return links\n",
    "\n",
    "# ----------------------------\n",
    "# Helper function\n",
    "# ----------------------------\n",
    "def predict_breed(img_path):\n",
    "    try:\n",
    "        # Load image as PIL Image first (like in working code)\n",
    "        img_pil = Image.open(img_path).convert(\"RGB\")\n",
    "        img_array = np.array(img_pil)\n",
    "\n",
    "        # Detect dog with YOLO\n",
    "        results = yolo(img_array)\n",
    "\n",
    "        # Check if any dogs were detected\n",
    "        if results[0].boxes is None:\n",
    "            return {\"error\": \"No dogs detected\"}\n",
    "\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        labels = results[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "        # Find the first dog (COCO class 16)\n",
    "        dog_box = None\n",
    "        for i, box in enumerate(boxes):\n",
    "            if int(labels[i]) == 16:  # COCO class 16 = dog\n",
    "                dog_box = box\n",
    "                break\n",
    "\n",
    "        if dog_box is None:\n",
    "            return {\"error\": \"No dog detected\"}\n",
    "\n",
    "        # Crop the dog region\n",
    "        x1, y1, x2, y2 = map(int, dog_box)\n",
    "\n",
    "        # Load image with OpenCV for cropping (like in working code)\n",
    "        img_cv = cv2.imread(img_path)\n",
    "        h, w, _ = img_cv.shape\n",
    "\n",
    "        # Ensure coordinates are within bounds\n",
    "        x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)\n",
    "\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return {\"error\": \"Invalid crop dimensions\"}\n",
    "\n",
    "        dog_crop = img_cv[y1:y2, x1:x2]\n",
    "\n",
    "        # Save cropped image temporarily\n",
    "        crop_path = \"temp_crop.jpg\"\n",
    "        cv2.imwrite(crop_path, dog_crop)\n",
    "\n",
    "        # Load and preprocess exactly like in working code\n",
    "        img = image.load_img(crop_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)  # Use ResNet50 preprocessing instead of /255.0\n",
    "\n",
    "        # Predict\n",
    "        preds = classifier.predict(x)\n",
    "        print(\"Check prediction---------->\", preds)\n",
    "\n",
    "        # Get top 3 predictions like in working code\n",
    "        probs = preds[0]\n",
    "        top_indices = probs.argsort()[-3:][::-1]  # Top 3 predictions\n",
    "\n",
    "        top_predictions = []\n",
    "        for idx in top_indices:\n",
    "            breed_name = BREED_CLASSES[idx]\n",
    "            confidence = float(probs[idx])\n",
    "            top_predictions.append({\n",
    "                \"breed\": breed_name,\n",
    "                \"confidence\": confidence\n",
    "            })\n",
    "\n",
    "        print(\"Check top predictions---------->\", top_predictions)\n",
    "\n",
    "        # Clean up temporary file\n",
    "        if os.path.exists(crop_path):\n",
    "            os.remove(crop_path)\n",
    "\n",
    "        # Get links for the predicted breed\n",
    "        breed_links = get_dog_links(top_predictions[0][\"breed\"])\n",
    "\n",
    "        return {\n",
    "            \"breed\": top_predictions[0][\"breed\"],\n",
    "            \"confidence\": top_predictions[0][\"confidence\"],\n",
    "            \"links\": breed_links\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in predict_breed: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# ----------------------------\n",
    "# Flask API\n",
    "# ----------------------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No file uploaded\"}), 400\n",
    "\n",
    "    f = request.files[\"file\"]\n",
    "    if f.filename == '':\n",
    "        return jsonify({\"error\": \"No file selected\"}), 400\n",
    "\n",
    "    filepath = os.path.join(\"uploads\", f.filename)\n",
    "    os.makedirs(\"uploads\", exist_ok=True)\n",
    "    f.save(filepath)\n",
    "\n",
    "    try:\n",
    "        result = predict_breed(filepath)\n",
    "        # Clean up uploaded file\n",
    "        if os.path.exists(filepath):\n",
    "            os.remove(filepath)\n",
    "        return jsonify(result)\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route(\"/breed-links/<breed_name>\", methods=[\"GET\"])\n",
    "def get_breed_links(breed_name):\n",
    "    \"\"\"Get adoption/purchase links for a specific breed\"\"\"\n",
    "    try:\n",
    "        links = get_dog_links(breed_name)\n",
    "        return jsonify({\n",
    "            \"breed\": breed_name,\n",
    "            \"links\": links\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route(\"/redirect/<link_type>/<breed_name>\", methods=[\"GET\"])\n",
    "def redirect_to_site(link_type, breed_name):\n",
    "    \"\"\"Direct redirect to specific adoption/purchase sites\"\"\"\n",
    "    from flask import redirect\n",
    "\n",
    "    try:\n",
    "        links = get_dog_links(breed_name)\n",
    "\n",
    "        # Define redirect mappings\n",
    "        redirect_map = {\n",
    "            \"petfinder\": links[\"adoption\"][\"petfinder\"],\n",
    "            \"adoptapet\": links[\"adoption\"][\"adopt_a_pet\"],\n",
    "            \"akc-marketplace\": links[\"purchase\"][\"akc_marketplace\"],\n",
    "            \"puppyfind\": links[\"purchase\"][\"puppyfind\"],\n",
    "            \"breed-info\": links[\"breed_info\"][\"akc_info\"]\n",
    "        }\n",
    "\n",
    "        if link_type in redirect_map:\n",
    "            return redirect(redirect_map[link_type])\n",
    "        else:\n",
    "            return jsonify({\"error\": \"Invalid link type\"}), 400\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMrbhZff7gFuj/HbZ0Mmo1h",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
